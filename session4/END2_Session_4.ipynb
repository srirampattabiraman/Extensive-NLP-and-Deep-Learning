{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END2 Session 4.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srirampattabiraman/Extensive-NLP-and-Deep-Learning/blob/main/session4/END2_Session_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SPhj6gnAnT2"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "TEXT = data.Field(tokenize = 'spacy',\n",
        "                  tokenizer_language = 'en_core_web_sm')\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwn4oStE6PzV",
        "outputId": "576ae3a6-c0c6-42c2-db25-39d1b0c68cf8"
      },
      "source": [
        "from torchtext.legacy import datasets\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:01<00:00, 55.7MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DLJ86m56Xdn",
        "outputId": "aacfb026-14e9-43ff-f94d-eed18e33a84d"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 25000\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXTWwqXA6rP2",
        "outputId": "dffa9781-267c-4ee3-eac0-7ad7733758eb"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['Before', 'Cujo', ',', 'there', 'was', 'Lucky', 'the', 'devil', 'dog', '.', 'In', '1978,on', 'Halloween', 'night', 'the', 'movie\"Devil', 'Dog', ',', 'The', 'Hound', 'of', 'Hell', '\"', 'premiered', '.', 'A', 'story', 'of', 'a', 'family', 'getting', 'a', 'new', 'puppy', '(', 'from', 'a', 'farmer', 'who', 'just', 'happen', 'to', 'be', 'in', 'the', 'neighborhood', 'selling', 'fruits', 'and', 'vegetables', ')', 'because', 'their', 'dog', 'Skipper', 'was', 'killed', '.', 'Coencidence', '?', 'Everyone', 'loves', 'the', 'new', 'dog', ',', 'but', 'there', 'is', 'something', 'strange', 'about', 'him', '.', '<', 'br', '/><br', '/>It', 'is', \"n't\", 'long', 'until', 'the', 'father', 'Mike', 'Barry(Richard', 'Crenna', ',', 'First', 'Blood)starts', 'to', 'notice', '.', 'His', 'wife', 'Betty(Yvette', 'Mimieux', ',', 'Where', 'The', 'Boys', 'Are', ',', 'Jackson', 'County', 'Jail', ',', 'Snowbeast)is', 'different', 'and', 'his', 'kids', 'Charlie', 'and', 'Bonnie(Ike', 'Eisenman', ',', 'Witch', 'Mountain', 'and', 'Fantastic', 'Vourage', 'and', 'Kim', 'Richards', ',', 'Witch', 'Mountain', ',', 'Nanny', 'and', 'the', 'Professor', ',', 'Hello', 'Larry', ',', 'Tuff', '-', 'Turf)also', 'have', 'changed', '.', 'Does', 'the', 'dog', 'have', 'something', 'to', 'do', 'with', 'it', '?', 'He', \"'s\", 'determined', 'to', 'find', 'out', 'and', 'do', 'whatever', 'it', 'takes', 'to', 'save', 'his', 'family.<br', '/><br', '/>This', 'movie', 'is', 'great', 'because', 'it', 'has', 'Ike', 'and', 'Kim', 'playing', 'a', 'darker', 'side', 'of', 'themselves', 'than', 'what', 'we', 'saw', 'on', 'those', 'witch', 'mountain', 'movies', '.', 'This', 'is', 'one', 'of', 'the', 'many', '70', \"'s\", 'made', '-', 'for', '-', 'TV', 'horror', 'movies', 'that', 'was', 'actually', 'scary', 'for', 'a', 'made', '-', 'for', '-', 'TV', 'horror', 'movie', '.', 'The', 'music', 'was', 'creepy', 'and', 'even', 'the', 'ending', 'which', 'I', 'wo', \"n't\", 'tell', 'made', 'you', 'think.<br', '/><br', '/>This', 'movie', 'also', 'stars', 'Ken', 'Kercheval(Cliff', 'Barnes', 'of', 'Dallas)and', 'R.G.', 'Armstrong(who', 'could', \"n't\", 'stay', 'away', 'from', 'devil', 'movies', 'remember\"Race', 'with', 'the', 'Devil\"?)<br', '/><br', '/>It', \"'s\", 'worth', 'watching', '.'], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HMVqiZd6tR0"
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOeQ6KpP7M-0",
        "outputId": "b226b485-65ed-4a2e-fb21-fc32514097b6"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 17500\n",
            "Number of validation examples: 7500\n",
            "Number of testing examples: 25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KixkM1jQ7TB-"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "TEXT.build_vocab(train_data, max_size = MAX_VOCAB_SIZE)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD4SFKnc7g0D",
        "outputId": "6b8fb520-5203-4c02-d9fe-4dc80bd36b11"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttKvFTCQ7isK",
        "outputId": "327e2511-c511-4388-dd09-7a414d3f7cd8"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 203063), (',', 192343), ('.', 166129), ('and', 109794), ('a', 109526), ('of', 100808), ('to', 93971), ('is', 76428), ('in', 61581), ('I', 54306), ('it', 53609), ('that', 49177), ('\"', 44610), (\"'s\", 43276), ('this', 42373), ('-', 36806), ('/><br', 35659), ('was', 35096), ('as', 30590), ('with', 30113)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZXIsIV47mlI",
        "outputId": "c246aff7-7067-463b-c1dc-486898f58c2d"
      },
      "source": [
        "print(TEXT.vocab.itos[:10]) ## A list of token strings indexed by their numerical identifiers."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmbx3T9-7x4g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b34ea0-3b35-44dc-9432-4cd5710af3aa"
      },
      "source": [
        "print(LABEL.vocab.stoi) ## A collections.defaultdict instance mapping token strings to numerical identifiers."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(None, {'neg': 0, 'pos': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3gBfP6mEJ_0"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2ZQQV1-ELZf"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "        \n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, 128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.fc2 = nn.Linear(128, output_dim)\n",
        "        \n",
        "    def forward(self, text):\n",
        "\n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "\n",
        "        output, (hidden, cell_state) = self.lstm(embedded)\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim]\n",
        "        #hidden = [1, batch size, hid dim]\n",
        "\n",
        "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "        return self.fc2(self.fc1(hidden.squeeze(0)))"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0_X5kSwENad"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "model = LSTM(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdGb8dKBEO2x",
        "outputId": "459a78aa-97fd-4ede-a037-55290a8cf783"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,899,817 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAeEtXiJEQCj"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Utp4-qAERRG"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyAXf58FESdL"
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4yNiGXQETh9"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1iGJW1wEUrL"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "                \n",
        "        predictions = model(batch.text).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNQxQS3tEWUW"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVM8MtV6EYIw"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJ5KZmM4EZXW",
        "outputId": "b4b54e04-952c-41fe-b3a1-874ff3d9139c"
      },
      "source": [
        "N_EPOCHS = 30\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.694 | Train Acc: 49.89%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 49.71%\n",
            "Epoch: 02 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.94%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 49.72%\n",
            "Epoch: 03 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.693 | Train Acc: 49.97%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 49.19%\n",
            "Epoch: 04 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.25%\n",
            "\t Val. Loss: 0.702 |  Val. Acc: 51.58%\n",
            "Epoch: 05 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.692 | Train Acc: 50.50%\n",
            "\t Val. Loss: 0.697 |  Val. Acc: 51.73%\n",
            "Epoch: 06 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.691 | Train Acc: 50.51%\n",
            "\t Val. Loss: 0.698 |  Val. Acc: 52.36%\n",
            "Epoch: 07 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.689 | Train Acc: 50.48%\n",
            "\t Val. Loss: 0.731 |  Val. Acc: 52.94%\n",
            "Epoch: 08 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.689 | Train Acc: 50.81%\n",
            "\t Val. Loss: 0.720 |  Val. Acc: 51.97%\n",
            "Epoch: 09 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.688 | Train Acc: 50.47%\n",
            "\t Val. Loss: 0.714 |  Val. Acc: 52.36%\n",
            "Epoch: 10 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.686 | Train Acc: 50.72%\n",
            "\t Val. Loss: 0.756 |  Val. Acc: 52.67%\n",
            "Epoch: 11 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.686 | Train Acc: 51.09%\n",
            "\t Val. Loss: 0.748 |  Val. Acc: 52.93%\n",
            "Epoch: 12 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.685 | Train Acc: 50.93%\n",
            "\t Val. Loss: 0.777 |  Val. Acc: 53.01%\n",
            "Epoch: 13 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.686 | Train Acc: 50.55%\n",
            "\t Val. Loss: 0.753 |  Val. Acc: 54.25%\n",
            "Epoch: 14 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.660 | Train Acc: 58.45%\n",
            "\t Val. Loss: 0.689 |  Val. Acc: 65.65%\n",
            "Epoch: 15 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.547 | Train Acc: 73.41%\n",
            "\t Val. Loss: 0.627 |  Val. Acc: 70.18%\n",
            "Epoch: 16 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.390 | Train Acc: 83.89%\n",
            "\t Val. Loss: 0.523 |  Val. Acc: 78.23%\n",
            "Epoch: 17 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.256 | Train Acc: 90.55%\n",
            "\t Val. Loss: 0.534 |  Val. Acc: 79.29%\n",
            "Epoch: 18 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.174 | Train Acc: 94.15%\n",
            "\t Val. Loss: 0.601 |  Val. Acc: 80.25%\n",
            "Epoch: 19 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.122 | Train Acc: 96.16%\n",
            "\t Val. Loss: 0.610 |  Val. Acc: 80.79%\n",
            "Epoch: 20 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.072 | Train Acc: 98.14%\n",
            "\t Val. Loss: 0.717 |  Val. Acc: 80.24%\n",
            "Epoch: 21 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.060 | Train Acc: 98.44%\n",
            "\t Val. Loss: 0.818 |  Val. Acc: 77.19%\n",
            "Epoch: 22 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.057 | Train Acc: 98.43%\n",
            "\t Val. Loss: 0.796 |  Val. Acc: 79.14%\n",
            "Epoch: 23 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.039 | Train Acc: 99.06%\n",
            "\t Val. Loss: 0.796 |  Val. Acc: 80.31%\n",
            "Epoch: 24 | Epoch Time: 0m 29s\n",
            "\tTrain Loss: 0.024 | Train Acc: 99.49%\n",
            "\t Val. Loss: 0.863 |  Val. Acc: 81.93%\n",
            "Epoch: 25 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.019 | Train Acc: 99.61%\n",
            "\t Val. Loss: 0.805 |  Val. Acc: 81.50%\n",
            "Epoch: 26 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.015 | Train Acc: 99.66%\n",
            "\t Val. Loss: 1.024 |  Val. Acc: 80.00%\n",
            "Epoch: 27 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.023 | Train Acc: 99.42%\n",
            "\t Val. Loss: 0.889 |  Val. Acc: 77.82%\n",
            "Epoch: 28 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.030 | Train Acc: 99.13%\n",
            "\t Val. Loss: 0.907 |  Val. Acc: 80.77%\n",
            "Epoch: 29 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.014 | Train Acc: 99.69%\n",
            "\t Val. Loss: 0.942 |  Val. Acc: 81.95%\n",
            "Epoch: 30 | Epoch Time: 0m 28s\n",
            "\tTrain Loss: 0.008 | Train Acc: 99.84%\n",
            "\t Val. Loss: 0.989 |  Val. Acc: 81.67%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIiKAJMaEbKO",
        "outputId": "7979fd55-3978-44a5-dfba-7432208aa086"
      },
      "source": [
        " model.load_state_dict(torch.load('tut1-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.629 | Test Acc: 75.30%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX5mLZ7utz6Y"
      },
      "source": [
        "Observations:\n",
        "\n",
        "1. Just by adding LSTM layer along with fully connected layer accuracy saturated at 50% irrespective of epochs\n",
        "Results below\n",
        "====\n",
        "  Epoch: 27 | Epoch Time: 0m 28s\n",
        "\t  Train Loss: 0.693 | Train Acc: 50.36%\n",
        "\t  Val. Loss: 0.693 |  Val. Acc: 50.17%\n",
        "  \n",
        "  Epoch: 28 | Epoch Time: 0m 28s\n",
        "\t  Train Loss: 0.693 | Train Acc: 50.36%\n",
        "\t  Val. Loss: 0.693 |  Val. Acc: 50.20%\n",
        "  \n",
        "  Epoch: 29 | Epoch Time: 0m 28s\n",
        "\t  Train Loss: 0.693 | Train Acc: 50.44%\n",
        "\t  Val. Loss: 0.693 |  Val. Acc: 50.16%\n",
        "  \n",
        "  Epoch: 30 | Epoch Time: 0m 28s\n",
        "\t  Train Loss: 0.693 | Train Acc: 50.40%\n",
        "\t  Val. Loss: 0.693 |  Val. Acc: 50.16% **bold text**\n",
        "\n",
        "2. Hence changed the optimizer from SGD to ADAM that possesses adaptive learning rate which eventually reduces loss upon epochs and considerable increase in validation accuracy is observed.\n",
        "\n",
        "3. Even though Training accuracy is improved after changing the activation function, test accuracy is very less. hence the model is overfitting (Low Bias and High variance)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G024NssCEcj0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}